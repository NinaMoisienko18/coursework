import streamlit as st
import cv2
from PIL import Image
import pytesseract
import base64
import tempfile
import numpy as np
import pandas as pd
import fitz  # –Ü–º–ø–æ—Ä—Ç PyMuPDF
from pdf2image import convert_from_path


pytesseract.pytesseract.tesseract_cmd = "/usr/local/bin/tesseract"

def perform_ocr(image_path, user_input_format):
    try:

        orig = cv2.imread(image_path)
        image = orig.copy()

        def define_format(user_input_format):
            if user_input_format == "–ß–µ–∫":
                config_1 = r'--psm 4 --oem 3'
                return config_1

            elif user_input_format == "PDF-–¥–æ–∫—É–º–µ–Ω—Ç":
                text = extract_text_from_pdf(image_path)
                return None, None, text

            elif user_input_format == "–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –ø—Ä–æ—Å—Ç–∏–º —Ç–µ–∫—Å—Ç–æ–º (–±–µ–∑ —Ç–∞–±–ª–∏—Ü—å —Ç–æ—â–æ)":
                config_1 = r'--psm 3 --oem 3'
                return config_1


        def get_grayscale(image):
            bgr_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            return cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)

        def thresholding(image):
            return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]

        def opening(image):
            kernel = np.ones((5, 5), np.uint8)
            return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)

        col1, col2 = st.columns(2)
        with col1:
            gray = get_grayscale(image)
            st.image(gray, caption=f"1. –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è —É –≤—ñ–¥—Ç—ñ–Ω–∫–∞—Ö —Å—ñ—Ä–æ–≥–æ", use_column_width=True)

        with col2:
            thresh = thresholding(gray)
            st.image(thresh, caption=f"2. –ü–æ—Ä–æ–≥–æ–≤–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –ø—ñ—Å–ª—è –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è —Ñ—ñ–ª—å—Ç—Ä—É", use_column_width=True)

        with col1:
            opened = opening(gray)
            st.image(opened, caption=f"3. –í—ñ–¥–∫—Ä–∏—Ç—Ç—è - –ø—ñ—Å–ª—è –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –º–æ—Ä—Ñ–æ–ª–æ–≥—ñ—á–Ω–æ–≥–æ –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è",
                     use_column_width=True)

        text5 = pytesseract.image_to_string(cv2.cvtColor(thresh, cv2.COLOR_BGR2RGB), lang="ukr+eng",
                                            config=define_format(user_input_format))

        results = pytesseract.image_to_data(thresh, output_type=pytesseract.Output.DICT)
        boxes = [((results['left'][i], results['top'][i]),
                  (results['left'][i] + results['width'][i], results['top'][i] + results['height'][i]))
                 for i in range(len(results['text'])) if int(results['conf'][i]) > 0]

        return thresh, boxes, text5
    except Exception as e:
        return f"–ü–æ–º–∏–ª–∫–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É: {str(e)}", None, None

def extract_text_from_pdf(pdf_path, num_pages=None):
    text = ""
    pdf_document = fitz.open(pdf_path)
    num_pages = min(num_pages, len(pdf_document)) if num_pages is not None else len(pdf_document)
    for page_num in range(num_pages):
        page = pdf_document[page_num]
        text += page.get_text("text")  # –î–æ–¥–∞–Ω–æ –ø–∞—Ä–∞–º–µ—Ç—Ä "text" –¥–ª—è –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ —Ä—ñ–∑–Ω–∏—Ö –º–æ–≤
    return text

def convert_pdf_to_image(pdf_path, page_number=0):
    images = convert_from_path(pdf_path, first_page=page_number+1, last_page=page_number+1)
    return images[0]


def display_ocr_image(thresh, boxes, text):
    img_np = np.array(thresh)  # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —É numpy array
    col1, col2, col3 = st.columns((0.5, 2, 0.5))
    with col2:
        img_with_rectangles = img_np.copy()  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ numpy array –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ OpenCV

        for box in boxes:
            cv2.rectangle(img_with_rectangles, box[0], box[1], (0, 255, 0), 2)

        st.markdown(" ")
        st.markdown(" ")

        st.image(img_with_rectangles, use_column_width=True)

main_bg = "background.png"

def get_base64(bin_file):
    with open(bin_file, 'rb') as f:
        data = f.read()
    return base64.b64encode(data).decode()

def set_background(png_file):
    bin_str = get_base64(png_file)
    page_bg_img = '''
    <style>
    .stApp {
    background-image: url("data:image/png;base64,%s");
    background-size: cover;
    }
    </style>
    ''' % get_base64(png_file)
    st.markdown(page_bg_img, unsafe_allow_html=True)

st.markdown("")
st.markdown(
    "<h1 style='color: #000000; text-align: center; font-size: 35px''>–†–æ–∑–ø—ñ–∑–Ω–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è—Ö —Ç–∞ PDF-—Ñ–∞–π–ª–∞—Ö [üßæ]</h1>",
    unsafe_allow_html=True)
st.markdown("")
st.markdown(
    "<div style='text-align: justify; font-size: 18px'><b>üìåText Recognition App</b> - —Ü–µ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∏–π –¥–æ–¥–∞—Ç–æ–∫,"
    " —è–∫–∏–π —Å—Ç–≤–æ—Ä–µ–Ω–∏–π –∑ –º–µ—Ç–æ—é –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É —ñ–∑ –∑–æ–±—Ä–∞–∂–µ–Ω—å —Ç–∞ PDF-—Ñ–∞–π–ª—ñ–≤, –∑–Ω–∞—á–Ω–æ –∑–µ–∫–æ–Ω–æ–º–∏—Ç—å —á–∞—Å —Ç–∞ –∑—É—Å–∏–ª–ª—è –ø—Ä–∏ –≤–Ω–µ—Å–µ–Ω–Ω—ñ –¥–∞–Ω–∏—Ö! </div>",
    unsafe_allow_html=True)
st.markdown("")

selection = st.selectbox("–û–±–µ—Ä—ñ—Ç—å –∑—Ä—É—á–Ω–∏–π —Å–ø–æ—Å—ñ–± –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–æ—Ç–æ —É –ø—Ä–æ–≥—Ä–∞–º—É üëá",
                        ["–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ñ–æ—Ç–æ üíª", "–ó—Ä–æ–±–∏—Ç–∏ —Ñ–æ—Ç–æ üì∏", "–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ PDF-–¥–æ–∫—É–º–µ–Ω—Ç"], key="photo_selection")

user_input_format = None
data = None
if selection == "–ó—Ä–æ–±–∏—Ç–∏ —Ñ–æ—Ç–æ üì∏":
    data = st.camera_input("–ù–∞–≤–µ–¥–∏ –∫–∞–º–µ—Ä—É –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—É —á–∞—Å—Ç–∏–Ω—É")
elif selection == "–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ñ–æ—Ç–æ üíª":
    data = st.file_uploader("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–æ—Ç–æ", type=['png', 'jpg', 'jpeg'], key="photo_uploader")
    user_input_format = st.selectbox("–§–æ—Ä–º–∞—Ç –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è",
                                     ["–ß–µ–∫", "–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –ø—Ä–æ—Å—Ç–∏–º —Ç–µ–∫—Å—Ç–æ–º (–±–µ–∑ —Ç–∞–±–ª–∏—Ü—å —Ç–æ—â–æ)"])

elif selection == "–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ PDF-–¥–æ–∫—É–º–µ–Ω—Ç":
    data = st.file_uploader("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–∞–π–ª", type=['pdf'], key="document_uploader")

if data:
    if selection == "–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ PDF-–¥–æ–∫—É–º–µ–Ω—Ç":
        num_pages = st.number_input("–í–≤–µ–¥—ñ—Ç—å –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Å—Ç–æ—Ä—ñ–Ω–æ–∫ –¥–ª—è –æ–±—Ä–æ–±–∫–∏", min_value=1, max_value=100, value=1, step=1)

        with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_file:
            temp_file.write(data.getvalue())
            temp_file_path = temp_file.name


        text = extract_text_from_pdf(temp_file_path, num_pages)

        st.markdown("<h4 style='color: #000000; text-align: center;'>–ó–Ω–∞–π–¥–µ–Ω–∏–π —Ç–µ–∫—Å—Ç:</h4>", unsafe_allow_html=True)
        text_area = st.code(text)
        st.markdown("")
    else:
        img = Image.open(data)
        with tempfile.NamedTemporaryFile(suffix='.jpeg', delete=False) as temp_file:
            temp_file.write(data.getvalue())
            temp_file_path = temp_file.name

        img_ocr, boxes, text = perform_ocr(temp_file_path, user_input_format)

        if img is not None:
            display_ocr_image(img_ocr, boxes, text)

        if text:
            st.markdown("<h4 style='color: #000000; text-align: center;'>–ó–Ω–∞–π–¥–µ–Ω–∏–π —Ç–µ–∫—Å—Ç:</h4>", unsafe_allow_html=True)
            text_area = st.code(text)
            st.markdown("")

        if st.button("–ï–∫—Å–ø–æ—Ä—Ç —É —Ñ–∞–π–ª", help="–ï–∫—Å–ø–æ—Ä—Ç —Ç–µ–∫—Å—Ç—É —É –≤–∏–±—Ä–∞–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª—É", key="export_button"):
            file_type = st.selectbox("–û–±–µ—Ä—ñ—Ç—å —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª—É", ["txt"], key="file_type")
            if file_type == "txt":
                with open("extracted_text.txt", "w") as f:
                    f.write(text)
                st.success("–¢–µ–∫—Å—Ç —É—Å–ø—ñ—à–Ω–æ –µ–∫—Å–ø–æ—Ä—Ç–æ–≤–∞–Ω–æ —É —Ñ–æ—Ä–º–∞—Ç—ñ TXT.")

set_background(main_bg)