import streamlit as st
import cv2
from PIL import Image
import pytesseract
import base64
import tempfile
import numpy as np
import pandas as pd
import fitz  # –Ü–º–ø–æ—Ä—Ç PyMuPDF
from pdf2image import convert_from_path

pytesseract.pytesseract.tesseract_cmd = "/usr/local/bin/tesseract"


def perform_ocr(image_path, user_input_format):
    try:
        st.markdown(
            "<h1 style='color: #000000; text-align: center; font-size: 20px''>–ü–æ–ø–µ—Ä–µ–¥–Ω—è –æ–±—Ä–æ–±–∫–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è ‚¨áÔ∏è</h1>",
            unsafe_allow_html=True)

        # –í–∏–∫–ª–∏–∫–∞—î–º–æ —Ñ—É–Ω–∫—Ü—ñ—é set_image_dpi –¥–ª—è –∑–º—ñ–Ω–∏ —Ä–æ–∑–¥—ñ–ª—å–Ω–æ—ó –∑–¥–∞—Ç–Ω–æ—Å—Ç—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è

        orig = cv2.imread(image_path)
        image = orig.copy()

        def define_format(user_input_format):
            if user_input_format == "–ß–µ–∫":
                config_1 = r'--psm 4 --oem 3'
                return config_1

            elif user_input_format == "PDF-–¥–æ–∫—É–º–µ–Ω—Ç":
                text = extract_text_from_pdf(image_path)
                return None, None, text

            elif user_input_format == "–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –ø—Ä–æ—Å—Ç–∏–º —Ç–µ–∫—Å—Ç–æ–º (–±–µ–∑ —Ç–∞–±–ª–∏—Ü—å —Ç–æ—â–æ)":
                config_1 = r'--psm 3 --oem 3'
                return config_1

        def normalization(image):
            norm_img = np.zeros((image.shape[0], image.shape[1]))
            return cv2.normalize(image, norm_img, 0, 255, cv2.NORM_MINMAX)

        col1, col2, col3 = st.columns((1, 3, 1))
        with col2:
            normalixation_img = normalization(image)
            st.image(normalixation_img, caption=f"1 –ö—Ä–æ–∫ - –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è", use_column_width=True)

            text = pytesseract.image_to_string(cv2.cvtColor(normalixation_img, cv2.COLOR_BGR2RGB), lang="ukr+eng",
                                                config=define_format(user_input_format))

            results = pytesseract.image_to_data(normalixation_img, output_type=pytesseract.Output.DICT)
            boxes = [((results['left'][i], results['top'][i]),
                      (results['left'][i] + results['width'][i], results['top'][i] + results['height'][i]))
                     for i in range(len(results['text'])) if int(results['conf'][i]) > 0]

            display_ocr_image(normalixation_img, boxes, text)

        def remove_noise(image):
            try:
                remove_noise_img = cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 15)
                return remove_noise_img
            except Exception as e:
                return f"–ü–æ–º–∏–ª–∫–∞ –≤–∏–¥–∞–ª–µ–Ω–Ω—è —à—É–º—ñ–≤: {str(e)}", None, None

        col1, col2, col3 = st.columns((1, 3, 1))
        with col2:
            remove_noise_img = remove_noise(image)
            st.image(remove_noise_img, caption=f"2 –ö—Ä–æ–∫ - –í–∏–¥–∞–ª–µ–Ω–Ω—è —à—É–º—ñ–≤", use_column_width=True)

            text = pytesseract.image_to_string(cv2.cvtColor(remove_noise_img, cv2.COLOR_BGR2RGB), lang="ukr+eng",
                                               config=define_format(user_input_format))

            results = pytesseract.image_to_data(remove_noise_img, output_type=pytesseract.Output.DICT)
            boxes = [((results['left'][i], results['top'][i]),
                      (results['left'][i] + results['width'][i], results['top'][i] + results['height'][i]))
                     for i in range(len(results['text'])) if int(results['conf'][i]) > 0]

            display_ocr_image(remove_noise_img, boxes, text)
            # return remove_noise_img, boxes, text

        def get_grayscale(image):
            try:
                gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                denoised_image = cv2.medianBlur(gray_image, 5)

                return denoised_image
            except Exception as e:
                return f"–ü–æ–º–∏–ª–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó –≤ –≤—ñ–¥—Ç—ñ–Ω–∫–∏ —Å—ñ—Ä–æ–≥–æ: {str(e)}", None, None

        col1, col2, col3 = st.columns((1, 3, 1))
        with col2:
            gray_img = get_grayscale(image)
            st.image(gray_img, caption=f"–ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤ –≤—ñ–¥—Ç—ñ–Ω–∫–∏ —Å—ñ—Ä–æ–≥–æ", use_column_width=True)

            text = pytesseract.image_to_string(gray_img, lang="ukr+eng",
                                               config=define_format(user_input_format))

            results = pytesseract.image_to_data(gray_img, output_type=pytesseract.Output.DICT)
            boxes = [((results['left'][i], results['top'][i]),
                      (results['left'][i] + results['width'][i], results['top'][i] + results['height'][i]))
                     for i in range(len(results['text'])) if int(results['conf'][i]) > 0]

            display_ocr_image(gray_img, boxes, text)

        def thresholding(image):
            try:
                gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                denoised_image = cv2.medianBlur(gray_image, 5)
                _, thresholded_image = cv2.threshold(denoised_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                return thresholded_image
            except Exception as e:
                return f"–ü–æ–º–∏–ª–∫–∞ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –ø–æ—Ä–æ–≥–æ–≤–æ—ó –æ–±—Ä–æ–±–∫–∏: {str(e)}", None, None

        col1, col2, col3 = st.columns((1, 3, 1))
        with col2:
            thresholded_img = thresholding(image)
            st.image(thresholded_img, caption=f"–ü–æ—Ä–æ–≥–æ–≤–∞ –æ–±—Ä–æ–±–∫–∞", use_column_width=True)

            text = pytesseract.image_to_string(thresholded_img, lang="ukr+eng",
                                               config=define_format(user_input_format))

            results = pytesseract.image_to_data(thresholded_img, output_type=pytesseract.Output.DICT)
            boxes = [((results['left'][i], results['top'][i]),
                      (results['left'][i] + results['width'][i], results['top'][i] + results['height'][i]))
                     for i in range(len(results['text'])) if int(results['conf'][i]) > 0]

            display_ocr_image(thresholded_img, boxes, text)
            return thresholded_img, boxes, text

    except Exception as e:
        return f"–ü–æ–º–∏–ª–∫–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É: {str(e)}", None, None
def extract_text_from_pdf(pdf_path, num_pages=None):
    text = ""
    pdf_document = fitz.open(pdf_path)
    num_pages = min(num_pages, len(pdf_document)) if num_pages is not None else len(pdf_document)
    for page_num in range(num_pages):
        page = pdf_document[page_num]
        text += page.get_text("text")  # –î–æ–¥–∞–Ω–æ –ø–∞—Ä–∞–º–µ—Ç—Ä "text" –¥–ª—è –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ —Ä—ñ–∑–Ω–∏—Ö –º–æ–≤
    return text


def convert_pdf_to_image(pdf_path, page_number=0):
    images = convert_from_path(pdf_path, first_page=page_number + 1, last_page=page_number + 1)
    return images[0]


def display_ocr_image(thresh, boxes, text):
    img_np = np.array(thresh)  # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —É numpy array

    img_with_rectangles = img_np.copy()  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ numpy array –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ OpenCV

    for box in boxes:
        cv2.rectangle(img_with_rectangles, box[0], box[1], (0, 255, 255), 2)
    st.markdown(" ")
    st.image(img_with_rectangles, use_column_width=True)


main_bg = "background.png"


def get_base64(bin_file):
    with open(bin_file, 'rb') as f:
        data = f.read()
    return base64.b64encode(data).decode()


def set_background(png_file):
    bin_str = get_base64(png_file)
    page_bg_img = '''
    <style>
    .stApp {
    background-image: url("data:image/png;base64,%s");
    background-size: cover;
    }
    </style>
    ''' % get_base64(png_file)
    st.markdown(page_bg_img, unsafe_allow_html=True)


st.markdown("")
st.markdown(
    "<h1 style='color: #000000; text-align: center; font-size: 35px''>–†–æ–∑–ø—ñ–∑–Ω–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è—Ö —Ç–∞ PDF-—Ñ–∞–π–ª–∞—Ö [üßæ]</h1>",
    unsafe_allow_html=True)
st.markdown("")
st.markdown(
    "<div style='text-align: justify; font-size: 18px'><b>üìåText Recognition App</b> - —Ü–µ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∏–π –¥–æ–¥–∞—Ç–æ–∫,"
    " —è–∫–∏–π —Å—Ç–≤–æ—Ä–µ–Ω–∏–π –∑ –º–µ—Ç–æ—é –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É —ñ–∑ –∑–æ–±—Ä–∞–∂–µ–Ω—å —Ç–∞ PDF-—Ñ–∞–π–ª—ñ–≤, –∑–Ω–∞—á–Ω–æ –∑–µ–∫–æ–Ω–æ–º–∏—Ç—å —á–∞—Å —Ç–∞ –∑—É—Å–∏–ª–ª—è –ø—Ä–∏ –≤–Ω–µ—Å–µ–Ω–Ω—ñ –¥–∞–Ω–∏—Ö! </div>",
    unsafe_allow_html=True)
st.markdown("")

selection = st.selectbox("–û–±–µ—Ä—ñ—Ç—å –∑—Ä—É—á–Ω–∏–π —Å–ø–æ—Å—ñ–± –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–æ—Ç–æ —É –ø—Ä–æ–≥—Ä–∞–º—É üëá",
                         ["–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ñ–æ—Ç–æ üíª", "–ó—Ä–æ–±–∏—Ç–∏ —Ñ–æ—Ç–æ üì∏", "–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ PDF-–¥–æ–∫—É–º–µ–Ω—Ç"], key="photo_selection")

user_input_format = None
data = None
if selection == "–ó—Ä–æ–±–∏—Ç–∏ —Ñ–æ—Ç–æ üì∏":
    data = st.camera_input("–ù–∞–≤–µ–¥–∏ –∫–∞–º–µ—Ä—É –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—É —á–∞—Å—Ç–∏–Ω—É")
elif selection == "–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ñ–æ—Ç–æ üíª":
    data = st.file_uploader("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–æ—Ç–æ", type=['png', 'jpg', 'jpeg'], key="photo_uploader")
    user_input_format = st.selectbox("–§–æ—Ä–º–∞—Ç –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è",
                                     ["–ß–µ–∫", "–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –ø—Ä–æ—Å—Ç–∏–º —Ç–µ–∫—Å—Ç–æ–º (–±–µ–∑ —Ç–∞–±–ª–∏—Ü—å —Ç–æ—â–æ)"])

elif selection == "–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ PDF-–¥–æ–∫—É–º–µ–Ω—Ç":
    data = st.file_uploader("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–∞–π–ª", type=['pdf'], key="document_uploader")

if data:
    if selection == "–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ PDF-–¥–æ–∫—É–º–µ–Ω—Ç":
        num_pages = st.number_input("–í–≤–µ–¥—ñ—Ç—å –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Å—Ç–æ—Ä—ñ–Ω–æ–∫ –¥–ª—è –æ–±—Ä–æ–±–∫–∏", min_value=1, max_value=100, value=1,
                                    step=1)

        with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_file:
            temp_file.write(data.getvalue())
            temp_file_path = temp_file.name

        text = extract_text_from_pdf(temp_file_path, num_pages)

        st.markdown("<h4 style='color: #000000; text-align: center;'>–ó–Ω–∞–π–¥–µ–Ω–∏–π —Ç–µ–∫—Å—Ç:</h4>", unsafe_allow_html=True)
        text_area = st.code(text)
        st.markdown("")
    else:
        img = Image.open(data)
        with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:
            temp_file.write(data.getvalue())
            temp_file_path = temp_file.name

        img_ocr, boxes, text = perform_ocr(temp_file_path, user_input_format)
        if img is not None:
            display_ocr_image(img_ocr, boxes, text)

        if text:
            st.markdown("<h4 style='color: #000000; text-align: center;'>–ó–Ω–∞–π–¥–µ–Ω–∏–π —Ç–µ–∫—Å—Ç:</h4>", unsafe_allow_html=True)
            text_area = st.code(text)
            st.markdown("")

        if st.button("–ï–∫—Å–ø–æ—Ä—Ç —É —Ñ–∞–π–ª", help="–ï–∫—Å–ø–æ—Ä—Ç —Ç–µ–∫—Å—Ç—É —É –≤–∏–±—Ä–∞–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª—É", key="export_button"):
            file_type = st.selectbox("–û–±–µ—Ä—ñ—Ç—å —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª—É", ["txt"], key="file_type")
            if file_type == "txt":
                with open("extracted_text.txt", "w") as f:
                    f.write(text)
                st.success("–¢–µ–∫—Å—Ç —É—Å–ø—ñ—à–Ω–æ –µ–∫—Å–ø–æ—Ä—Ç–æ–≤–∞–Ω–æ —É —Ñ–æ—Ä–º–∞—Ç—ñ TXT.")

set_background(main_bg)
